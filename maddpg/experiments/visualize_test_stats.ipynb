{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>timestep</th>\n",
       "      <th>agent1_x</th>\n",
       "      <th>agent1_y</th>\n",
       "      <th>agent2_x</th>\n",
       "      <th>agent2_y</th>\n",
       "      <th>agent3_x</th>\n",
       "      <th>agent3_y</th>\n",
       "      <th>land1_x</th>\n",
       "      <th>land1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>land3_y</th>\n",
       "      <th>reward_1</th>\n",
       "      <th>reward_2</th>\n",
       "      <th>reward_3</th>\n",
       "      <th>agent1_cum_reward</th>\n",
       "      <th>agent2_cum_reward</th>\n",
       "      <th>agent3_cum_reward</th>\n",
       "      <th>agent1_dist</th>\n",
       "      <th>agent2_dist</th>\n",
       "      <th>agent3_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.569010</td>\n",
       "      <td>0.215131</td>\n",
       "      <td>-0.650407</td>\n",
       "      <td>-0.312304</td>\n",
       "      <td>0.436089</td>\n",
       "      <td>-0.543599</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.386315</td>\n",
       "      <td>0.418206</td>\n",
       "      <td>0.547344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.483568</td>\n",
       "      <td>0.215382</td>\n",
       "      <td>-0.564262</td>\n",
       "      <td>-0.312430</td>\n",
       "      <td>0.434339</td>\n",
       "      <td>-0.543597</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.319244</td>\n",
       "      <td>0.336602</td>\n",
       "      <td>0.547548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.369608</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>-0.460854</td>\n",
       "      <td>-0.313397</td>\n",
       "      <td>0.432026</td>\n",
       "      <td>-0.543594</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.248180</td>\n",
       "      <td>0.242420</td>\n",
       "      <td>0.547827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.234602</td>\n",
       "      <td>0.215751</td>\n",
       "      <td>-0.335352</td>\n",
       "      <td>-0.312720</td>\n",
       "      <td>0.429292</td>\n",
       "      <td>-0.543592</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.217807</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>0.548172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.085972</td>\n",
       "      <td>0.217183</td>\n",
       "      <td>-0.192920</td>\n",
       "      <td>-0.310577</td>\n",
       "      <td>0.426246</td>\n",
       "      <td>-0.543696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>0.067165</td>\n",
       "      <td>0.271086</td>\n",
       "      <td>0.135088</td>\n",
       "      <td>0.548676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode  timestep  agent1_x  agent1_y  agent2_x  agent2_y  agent3_x  \\\n",
       "0        1         1 -0.569010  0.215131 -0.650407 -0.312304  0.436089   \n",
       "1        1         2 -0.483568  0.215382 -0.564262 -0.312430  0.434339   \n",
       "2        1         3 -0.369608  0.215556 -0.460854 -0.313397  0.432026   \n",
       "3        1         4 -0.234602  0.215751 -0.335352 -0.312720  0.429292   \n",
       "4        1         5 -0.085972  0.217183 -0.192920 -0.310577  0.426246   \n",
       "\n",
       "   agent3_y  land1_x  land1_y  ...   land3_y  reward_1  reward_2  reward_3  \\\n",
       "0 -0.543599      0.5      0.0  ... -0.433013  0.001955  0.001955  0.001955   \n",
       "1 -0.543597      0.5      0.0  ... -0.433013  0.005798  0.005798  0.005798   \n",
       "2 -0.543594      0.5      0.0  ... -0.433013  0.014924  0.014924  0.014924   \n",
       "3 -0.543592      0.5      0.0  ... -0.433013  0.024801  0.024801  0.024801   \n",
       "4 -0.543696      0.5      0.0  ... -0.433013  0.019687  0.019687  0.019687   \n",
       "\n",
       "   agent1_cum_reward  agent2_cum_reward  agent3_cum_reward  agent1_dist  \\\n",
       "0           0.001955           0.001955           0.001955     0.386315   \n",
       "1           0.007753           0.007753           0.007753     0.319244   \n",
       "2           0.022678           0.022678           0.022678     0.248180   \n",
       "3           0.047479           0.047479           0.047479     0.217807   \n",
       "4           0.067165           0.067165           0.067165     0.271086   \n",
       "\n",
       "   agent2_dist  agent3_dist  \n",
       "0     0.418206     0.547344  \n",
       "1     0.336602     0.547548  \n",
       "2     0.242420     0.547827  \n",
       "3     0.147497     0.548172  \n",
       "4     0.135088     0.548676  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pickle file from ./test_policy/test_trajectory.pkl\n",
    "with open('./test_policy/test_fully-connected_10/test_trajectory.pkl', 'rb') as f:\n",
    "    trajectories = pickle.load(f)\n",
    "\n",
    "episode = 20\n",
    "trajectory = trajectories[episode]\n",
    "\n",
    "# print(len(trajectory[-2]) ,trajectory[-2])\n",
    "# calculate cumulative reward for each agent until each timestep as additional columns\n",
    "for trajectory in trajectories:\n",
    "    for i in range(len(trajectory)):\n",
    "        trajectory[i].extend([sum([row[14] for row in trajectory[:i+1]]), sum([row[15] for row in trajectory[:i+1]]), sum([row[16] for row in trajectory[:i+1]])])\n",
    "\n",
    "# print(len(trajectory[-2]) ,trajectory[-2])\n",
    "\n",
    "\n",
    "for trajectory in trajectories:\n",
    "    for k in range(len(trajectory)):\n",
    "        dists = []\n",
    "        for i in range(3):\n",
    "            dist = []\n",
    "            for j in range(3):\n",
    "                # print(np.array(row[2+2*i:4+2*i]))\n",
    "                dist.append(np.linalg.norm(np.array(trajectory[k][2+2*i:4+2*i]) - np.array(trajectory[k][8+2*j:10+2*j])))\n",
    "            dists.append(min(dist))\n",
    "        # print(len(dists))\n",
    "        trajectory[k].extend(dists)\n",
    "\n",
    "\n",
    "# trajectory = [row.extend(distss[i]) for i, row in enumerate(trajectory)]\n",
    "\n",
    "print(len(trajectory[0]))\n",
    "\n",
    "# trajectories is a list of trajectories. Where each trajectory is a list of:\n",
    "# [timestep, agent1_x, agent1_y, agent2_x, agent2_y, agent3_x, agent3_y, landmark1_x, landmark1_y, landmark2_x, landmark2_y, landmark3_x, landmark3_y, reward_1, reward_2, reward_3]\n",
    "# convert trajectories to pd dataframe with columns: episode, timestep, agent1_x, agent1_y, agent2_x, agent2_y, agent3_x, agent3_y, reward_1, reward_2, reward_3\n",
    "# Flatten the nested list\n",
    "flattened_data = [tup for trajectory in trajectories for tup in trajectory]\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_data, columns=[ 'episode', 'timestep',\n",
    "                                            'agent1_x', 'agent1_y',\n",
    "                                            'agent2_x', 'agent2_y', \n",
    "                                            'agent3_x', 'agent3_y', \n",
    "                                            'land1_x', 'land1_y',\n",
    "                                            'land2_x', 'land2_y', \n",
    "                                            'land3_x', 'land3_y', \n",
    "                                            'reward_1', 'reward_2', 'reward_3',\n",
    "                                            'agent1_cum_reward', 'agent2_cum_reward', 'agent3_cum_reward',\n",
    "                                            'agent1_dist', 'agent2_dist', 'agent3_dist'])\n",
    "\n",
    "\n",
    "\n",
    "BLUE = [0, 0.4470, 0.7410]\n",
    "RED = [0.8500, 0.3250, 0.0980]\n",
    "YELLOW = [0.929, 0.6940, 0.1250]\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "episode = 923\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,4.5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "# plot the x,y trajectory of agents in episode 1 sorted by timestep using seaborn\n",
    "sns.lineplot(x=\"agent1_x\", y=\"agent1_y\", data=df[df['episode']==episode], sort=False, color=BLUE)\n",
    "sns.lineplot(x=\"agent2_x\", y=\"agent2_y\", data=df[df['episode']==episode], sort=False, color=RED)\n",
    "sns.lineplot(x=\"agent3_x\", y=\"agent3_y\", data=df[df['episode']==episode], sort=False, color=YELLOW)\n",
    "# mark the location of landmarks\n",
    "sns.scatterplot(x=\"land1_x\", y=\"land1_y\", data=df[df['episode']==episode], color='gray', s=300)\n",
    "sns.scatterplot(x=\"land2_x\", y=\"land2_y\", data=df[df['episode']==episode], color='gray', s=300)\n",
    "sns.scatterplot(x=\"land3_x\", y=\"land3_y\", data=df[df['episode']==episode], color='gray', s=300)\n",
    "# make axis equal and limit the axis to -1.0 to 1.0\n",
    "plt.axis('square')\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "# plot the reward of agents in episode 1 sorted by timestep using seaborn\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_1\", data=df[df['episode']==episode], sort=False, color=BLUE, label='agent1')\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_2\", data=df[df['episode']==episode], sort=False, color=RED, label='agent2')\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_3\", data=df[df['episode']==episode], sort=False, color=YELLOW, label='agent3')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('shared reward')\n",
    "plt.title('Episode {}'.format(episode))\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "# plot the distance to the closest landmark for each agent\n",
    "sns.lineplot(x=\"timestep\", y=\"agent1_dist\", data=df[df['episode']==episode], sort=False, color=BLUE, label='agent1')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent2_dist\", data=df[df['episode']==episode], sort=False, color=RED, label='agent2')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent3_dist\", data=df[df['episode']==episode], sort=False, color=YELLOW, label='agent3')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('distance to closest landmark')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior Reply Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m     pygame\u001b[39m.\u001b[39mquit()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m     main()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m     save_frames_to_video(frames,\u001b[39m'\u001b[39m\u001b[39mepisode_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.avi\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(episode))\n",
      "\u001b[1;32m/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m         running \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m clock\u001b[39m.\u001b[39;49mtick(\u001b[39m60\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m capture_frame(screen)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hossein/repos/reward-sharing-relational-networks/maddpg/experiments/visualize_test_stats.ipynb#W5sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Update current time\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib qt\n",
    "import pygame\n",
    "import time\n",
    "\n",
    "episode = 923\n",
    "# Sample trajectory data\n",
    "trajectory_ = trajectories[episode]\n",
    "# drop the first element of the list for each list item in trajectory\n",
    "trajectory_ = [t[1:] for t in trajectory_]\n",
    "\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "# Display settings\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Multi-Agent and Landmarks Animation\")\n",
    "\n",
    "# Colors\n",
    "BLUE = np.array([0, 0.4470*255, 0.7410*255])\n",
    "RED = np.array([0.8500*255, 0.3250*255, 0.0980*255])\n",
    "YELLOW = np.array([0.929*255, 0.6940*255, 0.1250*255])\n",
    "\n",
    "WHITE = (255, 255, 255)\n",
    "AGENTS_COLORS = [BLUE, RED, YELLOW]\n",
    "LANDMARK_COLORS = [(50, 50, 50), (50, 50, 50), (50, 50, 50)]\n",
    "BLACK = (20, 20, 20)\n",
    "\n",
    "frames = []\n",
    "\n",
    "\n",
    "\n",
    "# shift and scale the data (-1,1) to fit the screen size (0,500) and (0,500)\n",
    "\n",
    "SCALE_FACTOR = 200  # given our dimensions and trajectory range\n",
    "SCREEN_CENTER = (WIDTH // 2, HEIGHT // 2)\n",
    "\n",
    "# Choose a font (using a default system font here)\n",
    "font = pygame.font.SysFont(\"arial\", 16)\n",
    "\n",
    "def map_to_screen(pos):\n",
    "    \"\"\"Map a trajectory position to a screen position.\"\"\"\n",
    "    return int(pos[0] * SCALE_FACTOR + SCREEN_CENTER[0]), int(pos[1] * SCALE_FACTOR + SCREEN_CENTER[1])\n",
    "\n",
    "\n",
    "def draw_entity(screen, x, y, color, size=.2*SCALE_FACTOR):\n",
    "    pygame.draw.circle(screen, color, (int(x), int(y)), size)\n",
    "\n",
    "\n",
    "\n",
    "def display_text(text, x, y, color=BLACK):\n",
    "    \"\"\"Render and display text on the screen at specified coordinates.\"\"\"\n",
    "    text_surface = font.render(text, True, color)\n",
    "    screen.blit(text_surface, (x, y))\n",
    "\n",
    "def capture_frame(screen):\n",
    "    \"\"\"Capture the current Pygame screen frame.\"\"\"\n",
    "    frame = pygame.Surface(screen.get_size())\n",
    "    frame.blit(screen, (0, 0))\n",
    "    frames.append(frame)\n",
    "\n",
    "\n",
    "def save_frames_to_video(frames, filename, fps=30):\n",
    "    \"\"\"Save captured frames to a video file.\"\"\"\n",
    "    height, width = frames[0].get_size()\n",
    "    size = (width, height)\n",
    "    out = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
    "    for frame in frames:\n",
    "        # Convert Pygame surface to OpenCV format\n",
    "        frame_rgb = pygame.surfarray.array3d(frame)  \n",
    "        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame_bgr)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "def main():\n",
    "    time.sleep(5)\n",
    "    clock = pygame.time.Clock()\n",
    "    running = True\n",
    "    current_time = 0\n",
    "\n",
    "    while running:\n",
    "        screen.fill(WHITE)\n",
    "\n",
    "        \n",
    "        # Calculate the current positions of the agents and landmarks\n",
    "        for i in range(len(trajectory_) - 1):\n",
    "\n",
    "            cum_rew_1 = trajectory_[i][16]\n",
    "            cum_rew_2 = trajectory_[i][17]\n",
    "            cum_rew_3 = trajectory_[i][18]\n",
    "\n",
    "            \n",
    "\n",
    "            t0, *data0 = trajectory_[i]\n",
    "            t1, *data1 = trajectory_[i + 1]\n",
    "\n",
    "            if t0 <= current_time < t1:\n",
    "                alpha = (current_time - t0) / (t1 - t0)\n",
    "\n",
    "                # Drawing agents\n",
    "                for j in range(3):  \n",
    "                    x0, y0, x1, y1 = data0[j * 2], data0[j * 2 + 1], data1[j * 2], data1[j * 2 + 1]\n",
    "                    # r0, r1 = data0[12 + j], data1[12 + j]\n",
    "                    x = x0 * (1 - alpha) + x1 * alpha\n",
    "                    y = y0 * (1 - alpha) + y1 * alpha\n",
    "                    # r = r0 * (1 - alpha) + r1 * alpha\n",
    "                    r = data0[12 + j]\n",
    "                    screen_x, screen_y = map_to_screen((x, y))\n",
    "                    draw_entity(screen, screen_x, screen_y, AGENTS_COLORS[j])\n",
    "                    display_text(f\"{r:.4f}\", screen_x-25, screen_y-60)\n",
    "\n",
    "                # Drawing landmarks\n",
    "                for j in range(3):\n",
    "                    x0, y0, x1, y1 = data0[6 + j * 2], data0[7 + j * 2], data1[6 + j * 2], data1[7 + j * 2]\n",
    "                    x = x0 * (1 - alpha) + x1 * alpha\n",
    "                    y = y0 * (1 - alpha) + y1 * alpha\n",
    "                    screen_x, screen_y = map_to_screen((x, y))\n",
    "                    draw_entity(screen, screen_x, screen_y, LANDMARK_COLORS[j], size=.05*SCALE_FACTOR)\n",
    "\n",
    "                display_text(f\"agent 1 cumulative reward: {cum_rew_1:.2f}\", 370, 10)\n",
    "                display_text(f\"agent 2 cumulative reward: {cum_rew_2:.2f}\", 370, 30)\n",
    "                display_text(f\"agent 2 cumulative reward: {cum_rew_3:.2f}\", 370, 50)\n",
    "                display_text(f\"episode: {episode}\",10, 20)\n",
    "                display_text(f\"timestep: {i}\", 120, 20)\n",
    "\n",
    "        pygame.display.flip()   \n",
    "        capture_frame(screen)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        \n",
    "        clock.tick(60)\n",
    "        # Update current time\n",
    "        current_time += .1\n",
    "\n",
    "        # Exit loop when trajectory ends\n",
    "        if current_time > trajectory[-1][0]:\n",
    "            running = False\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    save_frames_to_video(frames,'episode_{}.avi'.format(episode))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors\n",
    "BLUE = [0, 0.4470, 0.7410]\n",
    "RED = [0.8500, 0.3250, 0.0980]\n",
    "YELLOW = [0.929, 0.6940, 0.1250]\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "plt.subplot(2,2,1)\n",
    "sns.lineplot(x=\"timestep\", y=\"agent1_dist\", data=df, errorbar=(\"sd\",1), sort=False, color=BLUE, label='agent1')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent2_dist\", data=df, errorbar=(\"sd\",1), sort=False, color=RED, label='agent2')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent3_dist\", data=df, errorbar=(\"sd\",1), sort=False, color=YELLOW, label='agent3')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('distance to closest landmark')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "# sns.violinplot(data=df, x=\"timestep\", y=\"reward_1\")\n",
    "sns.histplot(data=df[df['timestep']==70], x=\"agent1_cum_reward\", bins=70)\n",
    "plt.xlabel('agent 1 cum. shared reward')\n",
    "plt.ylabel('number of episodes')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "sns.lineplot(x=\"timestep\", y=\"agent1_cum_reward\", data=df, errorbar=(\"sd\",1), sort=False, color=BLUE, label='agent1')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent2_cum_reward\", data=df, errorbar=(\"sd\",1), sort=False, color=RED, label='agent2')\n",
    "sns.lineplot(x=\"timestep\", y=\"agent3_cum_reward\", data=df, errorbar=(\"sd\",1), sort=False, color=YELLOW, label='agent3')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('mean cumulative shared reward')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_1\", data=df, errorbar=(\"sd\",1), sort=False, color=BLUE, label='agent1')\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_2\", data=df, errorbar=(\"sd\",1), sort=False, color=RED, label='agent2')\n",
    "sns.lineplot(x=\"timestep\", y=\"reward_3\", data=df, errorbar=(\"sd\",1), sort=False, color=YELLOW, label='agent3')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('mean shared reward')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='agent1_cum_reward', ylabel='Count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>timestep</th>\n",
       "      <th>agent1_x</th>\n",
       "      <th>agent1_y</th>\n",
       "      <th>agent2_x</th>\n",
       "      <th>agent2_y</th>\n",
       "      <th>agent3_x</th>\n",
       "      <th>agent3_y</th>\n",
       "      <th>land1_x</th>\n",
       "      <th>land1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>land3_y</th>\n",
       "      <th>reward_1</th>\n",
       "      <th>reward_2</th>\n",
       "      <th>reward_3</th>\n",
       "      <th>agent1_cum_reward</th>\n",
       "      <th>agent2_cum_reward</th>\n",
       "      <th>agent3_cum_reward</th>\n",
       "      <th>agent1_dist</th>\n",
       "      <th>agent2_dist</th>\n",
       "      <th>agent3_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17359</th>\n",
       "      <td>248</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.543376</td>\n",
       "      <td>-1.027080</td>\n",
       "      <td>-2.965943</td>\n",
       "      <td>2.324070</td>\n",
       "      <td>1.973199</td>\n",
       "      <td>1.491431</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>2.765631e-69</td>\n",
       "      <td>2.765631e-69</td>\n",
       "      <td>2.765631e-69</td>\n",
       "      <td>4.652545e-13</td>\n",
       "      <td>4.652545e-13</td>\n",
       "      <td>4.652545e-13</td>\n",
       "      <td>0.662560</td>\n",
       "      <td>3.309448</td>\n",
       "      <td>2.096349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54109</th>\n",
       "      <td>773</td>\n",
       "      <td>70</td>\n",
       "      <td>0.521156</td>\n",
       "      <td>1.194668</td>\n",
       "      <td>2.440394</td>\n",
       "      <td>2.279588</td>\n",
       "      <td>2.603815</td>\n",
       "      <td>2.645601</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>2.284251e-94</td>\n",
       "      <td>2.284251e-94</td>\n",
       "      <td>2.284251e-94</td>\n",
       "      <td>4.739723e-10</td>\n",
       "      <td>4.739723e-10</td>\n",
       "      <td>4.739723e-10</td>\n",
       "      <td>1.083882</td>\n",
       "      <td>2.993602</td>\n",
       "      <td>3.380125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21909</th>\n",
       "      <td>313</td>\n",
       "      <td>70</td>\n",
       "      <td>0.326593</td>\n",
       "      <td>0.294468</td>\n",
       "      <td>1.628497</td>\n",
       "      <td>2.385157</td>\n",
       "      <td>1.166466</td>\n",
       "      <td>2.432902</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>1.484994e-57</td>\n",
       "      <td>1.484994e-57</td>\n",
       "      <td>1.484994e-57</td>\n",
       "      <td>1.280297e-09</td>\n",
       "      <td>1.280297e-09</td>\n",
       "      <td>1.280297e-09</td>\n",
       "      <td>0.341733</td>\n",
       "      <td>2.638651</td>\n",
       "      <td>2.450701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31009</th>\n",
       "      <td>443</td>\n",
       "      <td>70</td>\n",
       "      <td>0.322937</td>\n",
       "      <td>1.009739</td>\n",
       "      <td>1.187097</td>\n",
       "      <td>1.181089</td>\n",
       "      <td>0.841576</td>\n",
       "      <td>1.090427</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>2.242209e-17</td>\n",
       "      <td>2.242209e-17</td>\n",
       "      <td>2.242209e-17</td>\n",
       "      <td>3.335787e-08</td>\n",
       "      <td>3.335787e-08</td>\n",
       "      <td>3.335787e-08</td>\n",
       "      <td>0.812939</td>\n",
       "      <td>1.366409</td>\n",
       "      <td>1.142675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>465</td>\n",
       "      <td>70</td>\n",
       "      <td>0.698887</td>\n",
       "      <td>0.957473</td>\n",
       "      <td>0.645835</td>\n",
       "      <td>-1.117532</td>\n",
       "      <td>0.273729</td>\n",
       "      <td>-1.017848</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>4.507780e-13</td>\n",
       "      <td>4.507780e-13</td>\n",
       "      <td>4.507780e-13</td>\n",
       "      <td>8.347150e-08</td>\n",
       "      <td>8.347150e-08</td>\n",
       "      <td>8.347150e-08</td>\n",
       "      <td>0.977911</td>\n",
       "      <td>1.127008</td>\n",
       "      <td>0.785063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40529</th>\n",
       "      <td>579</td>\n",
       "      <td>70</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>-8.734472</td>\n",
       "      <td>-1.003702</td>\n",
       "      <td>1.211598</td>\n",
       "      <td>-1.096818</td>\n",
       "      <td>0.755905</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>3.297303e-312</td>\n",
       "      <td>3.297303e-312</td>\n",
       "      <td>3.297303e-312</td>\n",
       "      <td>1.231898e-07</td>\n",
       "      <td>1.231898e-07</td>\n",
       "      <td>1.231898e-07</td>\n",
       "      <td>8.350193</td>\n",
       "      <td>1.083634</td>\n",
       "      <td>0.906289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32059</th>\n",
       "      <td>458</td>\n",
       "      <td>70</td>\n",
       "      <td>0.552698</td>\n",
       "      <td>-2.500751</td>\n",
       "      <td>-0.547425</td>\n",
       "      <td>-2.889860</td>\n",
       "      <td>-0.302394</td>\n",
       "      <td>-2.563204</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>2.068707e-68</td>\n",
       "      <td>2.068707e-68</td>\n",
       "      <td>2.068707e-68</td>\n",
       "      <td>1.663775e-07</td>\n",
       "      <td>1.663775e-07</td>\n",
       "      <td>1.663775e-07</td>\n",
       "      <td>2.218077</td>\n",
       "      <td>2.474785</td>\n",
       "      <td>2.130835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19879</th>\n",
       "      <td>284</td>\n",
       "      <td>70</td>\n",
       "      <td>0.526848</td>\n",
       "      <td>-12.756290</td>\n",
       "      <td>0.383371</td>\n",
       "      <td>1.161758</td>\n",
       "      <td>-0.011709</td>\n",
       "      <td>0.929286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.476803e-06</td>\n",
       "      <td>1.476803e-06</td>\n",
       "      <td>1.476803e-06</td>\n",
       "      <td>12.347739</td>\n",
       "      <td>0.965520</td>\n",
       "      <td>0.550518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.445426</td>\n",
       "      <td>-0.482668</td>\n",
       "      <td>-0.291745</td>\n",
       "      <td>-1.404208</td>\n",
       "      <td>-0.019340</td>\n",
       "      <td>-1.138117</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>3.027747e-08</td>\n",
       "      <td>3.027747e-08</td>\n",
       "      <td>3.027747e-08</td>\n",
       "      <td>7.296082e-06</td>\n",
       "      <td>7.296082e-06</td>\n",
       "      <td>7.296082e-06</td>\n",
       "      <td>0.485744</td>\n",
       "      <td>0.972092</td>\n",
       "      <td>0.741873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29679</th>\n",
       "      <td>424</td>\n",
       "      <td>70</td>\n",
       "      <td>0.559180</td>\n",
       "      <td>0.025038</td>\n",
       "      <td>-0.964309</td>\n",
       "      <td>2.268821</td>\n",
       "      <td>-1.157550</td>\n",
       "      <td>1.924041</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433013</td>\n",
       "      <td>7.896722e-31</td>\n",
       "      <td>7.896722e-31</td>\n",
       "      <td>7.896722e-31</td>\n",
       "      <td>1.005137e-05</td>\n",
       "      <td>1.005137e-05</td>\n",
       "      <td>1.005137e-05</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>1.969880</td>\n",
       "      <td>1.745512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       episode  timestep  agent1_x   agent1_y  agent2_x  agent2_y  agent3_x  \\\n",
       "17359      248        70 -0.543376  -1.027080 -2.965943  2.324070  1.973199   \n",
       "54109      773        70  0.521156   1.194668  2.440394  2.279588  2.603815   \n",
       "21909      313        70  0.326593   0.294468  1.628497  2.385157  1.166466   \n",
       "31009      443        70  0.322937   1.009739  1.187097  1.181089  0.841576   \n",
       "32549      465        70  0.698887   0.957473  0.645835 -1.117532  0.273729   \n",
       "40529      579        70  0.650833  -8.734472 -1.003702  1.211598 -1.096818   \n",
       "32059      458        70  0.552698  -2.500751 -0.547425 -2.889860 -0.302394   \n",
       "19879      284        70  0.526848 -12.756290  0.383371  1.161758 -0.011709   \n",
       "5599        80        70  0.445426  -0.482668 -0.291745 -1.404208 -0.019340   \n",
       "29679      424        70  0.559180   0.025038 -0.964309  2.268821 -1.157550   \n",
       "\n",
       "       agent3_y  land1_x  land1_y  ...   land3_y       reward_1  \\\n",
       "17359  1.491431      0.5      0.0  ... -0.433013   2.765631e-69   \n",
       "54109  2.645601      0.5      0.0  ... -0.433013   2.284251e-94   \n",
       "21909  2.432902      0.5      0.0  ... -0.433013   1.484994e-57   \n",
       "31009  1.090427      0.5      0.0  ... -0.433013   2.242209e-17   \n",
       "32549 -1.017848      0.5      0.0  ... -0.433013   4.507780e-13   \n",
       "40529  0.755905      0.5      0.0  ... -0.433013  3.297303e-312   \n",
       "32059 -2.563204      0.5      0.0  ... -0.433013   2.068707e-68   \n",
       "19879  0.929286      0.5      0.0  ... -0.433013   0.000000e+00   \n",
       "5599  -1.138117      0.5      0.0  ... -0.433013   3.027747e-08   \n",
       "29679  1.924041      0.5      0.0  ... -0.433013   7.896722e-31   \n",
       "\n",
       "            reward_2       reward_3  agent1_cum_reward  agent2_cum_reward  \\\n",
       "17359   2.765631e-69   2.765631e-69       4.652545e-13       4.652545e-13   \n",
       "54109   2.284251e-94   2.284251e-94       4.739723e-10       4.739723e-10   \n",
       "21909   1.484994e-57   1.484994e-57       1.280297e-09       1.280297e-09   \n",
       "31009   2.242209e-17   2.242209e-17       3.335787e-08       3.335787e-08   \n",
       "32549   4.507780e-13   4.507780e-13       8.347150e-08       8.347150e-08   \n",
       "40529  3.297303e-312  3.297303e-312       1.231898e-07       1.231898e-07   \n",
       "32059   2.068707e-68   2.068707e-68       1.663775e-07       1.663775e-07   \n",
       "19879   0.000000e+00   0.000000e+00       1.476803e-06       1.476803e-06   \n",
       "5599    3.027747e-08   3.027747e-08       7.296082e-06       7.296082e-06   \n",
       "29679   7.896722e-31   7.896722e-31       1.005137e-05       1.005137e-05   \n",
       "\n",
       "       agent3_cum_reward  agent1_dist  agent2_dist  agent3_dist  \n",
       "17359       4.652545e-13     0.662560     3.309448     2.096349  \n",
       "54109       4.739723e-10     1.083882     2.993602     3.380125  \n",
       "21909       1.280297e-09     0.341733     2.638651     2.450701  \n",
       "31009       3.335787e-08     0.812939     1.366409     1.142675  \n",
       "32549       8.347150e-08     0.977911     1.127008     0.785063  \n",
       "40529       1.231898e-07     8.350193     1.083634     0.906289  \n",
       "32059       1.663775e-07     2.218077     2.474785     2.130835  \n",
       "19879       1.476803e-06    12.347739     0.965520     0.550518  \n",
       "5599        7.296082e-06     0.485744     0.972092     0.741873  \n",
       "29679       1.005137e-05     0.064258     1.969880     1.745512  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the episodes with the lost cumulative reward at the timestep 70\n",
    "df[df['timestep']==70].sort_values(by='agent1_cum_reward', ascending=True).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>land1_x</th>\n",
       "      <th>land1_y</th>\n",
       "      <th>land2_x</th>\n",
       "      <th>land2_y</th>\n",
       "      <th>land3_x</th>\n",
       "      <th>land3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.433013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   land1_x  land1_y  land2_x   land2_y  land3_x   land3_y\n",
       "0      0.5      0.0    -0.25  0.433013    -0.25 -0.433013"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print location of landmarks at timestep 70 episode 923\n",
    "df[(df['timestep']==1) & (df['episode']==1)][['land1_x', 'land1_y', 'land2_x', 'land2_y', 'land3_x', 'land3_y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   land1_x  land1_y  land2_x   land2_y  land3_x   land3_y\n",
      "0      0.5      0.0    -0.25  0.433013    -0.25 -0.433013\n"
     ]
    }
   ],
   "source": [
    "# plot a contour plot of the reward function as np.exp(-(d**2)/0.1) at the location of landmarks\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(df[(df['timestep']==1) & (df['episode']==1)][['land1_x', 'land1_y', 'land2_x', 'land2_y', 'land3_x', 'land3_y']])\n",
    "\n",
    "\n",
    "def reward_function(d):\n",
    "    return np.exp(-(d**2)/.1)\n",
    "\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = np.linspace(-2, 2, 100)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "lanmark_locations = [(0.5, 0.0), (-0.25, 0.433013), (-0.25, -0.433013)]\n",
    "\n",
    "# calculate the distance to the closest landmark for each point in the grid\n",
    "Z = np.zeros_like(X)\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(Y)):\n",
    "        dists = []\n",
    "        for k in range(3):\n",
    "            dists.append(np.linalg.norm(np.array([X[i,j], Y[i,j]]) - np.array(lanmark_locations[k])))\n",
    "        Z[i,j] = reward_function(min(dists))\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('individual reward')\n",
    "ax.view_init(60, 35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
